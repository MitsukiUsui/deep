{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function score in module score:\n",
      "\n",
      "score(model, size=None, **kwargs)\n",
      "    calculate F1-score　for each model on MNIST\n",
      "    \n",
      "    arguments:\n",
      "        model    :  model(train_X, train_y, test_X, **kwargs) -> pred_y\n",
      "        size       :  size of training data\n",
      "        **kwargs: arguments for given model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import score\n",
    "help(score.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.k-NNによるMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function knn in module mymodels.knn:\n",
      "\n",
      "knn(train_X, train_y, test_X, k_max=20)\n",
      "    train by k-nearest neighbor\n",
      "    \n",
      "    arguments:\n",
      "        k_max: k will be searched among [1,k_max]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mymodels import knn\n",
    "help(knn.knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN: k-NN learning with k-max = 10\n",
      "\tk = 1 : f1-score = 0.9747394957029032\n",
      "\tk = 2 : f1-score = 0.97130623224259\n",
      "\tk = 3 : f1-score = 0.9746793133050092\n",
      "\tk = 4 : f1-score = 0.9742037372251108\n",
      "\tk = 5 : f1-score = 0.9730133728336101\n",
      "\tk = 6 : f1-score = 0.9730732265352326\n",
      "\tk = 7 : f1-score = 0.9716965257608962\n",
      "\tk = 8 : f1-score = 0.9717485216430303\n",
      "\tk = 9 : f1-score = 0.9694667155416964\n",
      "\tk = 10 : f1-score = 0.9699269548339519\n",
      "DONE: prediction with k = 1\n",
      "0.973124117413\n"
     ]
    }
   ],
   "source": [
    "score.score(knn.knn, k_max=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.MLP (without tf) によるMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function mlp_notf in module mymodels.mlp_notf:\n",
      "\n",
      "mlp_notf(train_X, train_y, test_X, hid_dim=100, n_epochs=10, batch_size=100, eps=0.1)\n",
      "    train by multiple layer perceptron without tensorflow\n",
      "    \n",
      "    arguments:\n",
      "        hid_dim:     dimention of hidden layer\n",
      "        n_epochs:   number of epochs\n",
      "        batch_size:  batch size of stochastic gradient descent\n",
      "        eps:           training rate of back propagation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mymodels import mlp_notf\n",
    "help(mlp_notf.mlp_notf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN: MLP learning with hid_dim = 100, n_epochs = 10, batch_size = 20, eps = 0.1\n",
      "\titer 0 :  -7322.1078361\n",
      "\titer 1 :  -5873.96183754\n",
      "\titer 2 :  -5198.73903245\n",
      "\titer 3 :  -3912.4388732\n",
      "\titer 4 :  -3675.57799838\n",
      "\titer 5 :  -3043.83509204\n",
      "\titer 6 :  -2259.78376426\n",
      "\titer 7 :  -1739.67861665\n",
      "\titer 8 :  -1889.22532087\n",
      "\titer 9 :  -1281.71335623\n",
      "0.973022918398\n"
     ]
    }
   ],
   "source": [
    "score.score(mlp_notf.mlp_notf, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.MLP (with tf) によるMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function mlp in module mymodels.mlp:\n",
      "\n",
      "mlp(train_X, train_y, test_X, hid_dim=100, n_epochs=10, batch_size=100, eps=0.1)\n",
      "    train by multiple layer perceptron with tensorflow\n",
      "    \n",
      "    arguments:\n",
      "        hid_dim:     dimention of hidden layer\n",
      "        n_epochs:   number of epochs\n",
      "        batch_size:  batch size of stochastic gradient descent\n",
      "        eps:           training rate of back propagation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mymodels import mlp\n",
    "help(mlp.mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN: MLP learning with hid_dim = 100, n_epochs = 10, batch_size = 10, eps = 0.1\n",
      "\tEPOCH:: 1, Validation cost: 896.275, Validation F1: 0.952\n",
      "\tEPOCH:: 2, Validation cost: 818.018, Validation F1: 0.958\n",
      "\tEPOCH:: 3, Validation cost: 642.468, Validation F1: 0.967\n",
      "\tEPOCH:: 4, Validation cost: 618.515, Validation F1: 0.970\n",
      "\tEPOCH:: 5, Validation cost: 603.246, Validation F1: 0.971\n",
      "\tEPOCH:: 6, Validation cost: 638.350, Validation F1: 0.968\n",
      "\tEPOCH:: 7, Validation cost: 645.203, Validation F1: 0.969\n",
      "\tEPOCH:: 8, Validation cost: 654.242, Validation F1: 0.969\n",
      "\tEPOCH:: 9, Validation cost: 651.673, Validation F1: 0.969\n",
      "\tEPOCH:: 10, Validation cost: 588.262, Validation F1: 0.970\n",
      "0.972975887404\n"
     ]
    }
   ],
   "source": [
    "score.score(mlp.mlp, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CNNによるMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cnn in module mymodels.cnn:\n",
      "\n",
      "cnn(train_X, train_y, test_X, n_epochs=50, batch_size=100, eps=0.01)\n",
      "    train by convolutional neural network with tensorflow\n",
      "    \n",
      "    arguments:\n",
      "        n_epochs:   number of epochs\n",
      "        batch_size:  batch size of stochastic gradient descent\n",
      "        eps:           training rate of back propagation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mymodels import cnn\n",
    "help(cnn.cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN: CNN learning with n_epochs = 2, batch_size = 100, eps = 0.01\n",
      "\tEPOCH:: 1, Validation cost: 0.379, Validation F1: 0.880\n",
      "\tEPOCH:: 2, Validation cost: 0.256, Validation F1: 0.928\n",
      "0.923185560502\n"
     ]
    }
   ],
   "source": [
    "score.score(cnn.cnn, n_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
